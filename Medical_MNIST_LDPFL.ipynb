{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LDPFL on the Medical MNIST Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook shows how to run LDPFL on the Medical MNIST Dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Importing packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "#!/usr/bin/env python3\n",
    "# -*- coding: utf-8 -*-\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torch.nn.functional as F\n",
    "import torchvision.transforms as transforms\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data import DataLoader, random_split, Subset\n",
    "from torchvision import datasets\n",
    "from torchvision.datasets import MNIST\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data import Dataset, TensorDataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import numpy as np\n",
    "import math\n",
    "import time\n",
    "import os\n",
    "import random\n",
    "import statistics\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.io import loadmat\n",
    "from Medical_MNIST_FL import FedMLFunc as fl\n",
    "from Medical_MNIST_FL import Net as Net\n",
    "from tqdm import tqdm\n",
    "fl = fl()\n",
    "\n",
    "from collections import OrderedDict\n",
    "from collections import defaultdict\n",
    "from typing import List, Tuple\n",
    "\n",
    "\n",
    "from LDP_Functions import SRR\n",
    "from LDP_Functions import LDP_FL\n",
    "from LDP_Functions import GRR\n",
    "\n",
    "\n",
    "\n",
    "# print(\"flwr\", fl.__version__)\n",
    "print(\"numpy\", np.__version__)\n",
    "print(\"torch\", torch.__version__)\n",
    "print(\"torchvision\", torchvision.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# Checking the device\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print('Using device:', device)\n",
    "\n",
    "# Getting GPU usage information before computation\n",
    "if device.type == 'cuda':\n",
    "    for i in range(0,torch.cuda.device_count()):\n",
    "        print(torch.cuda.get_device_name(i))\n",
    "        print('Memory Usage of device :', i)\n",
    "        print('Allocated:', round(torch.cuda.memory_allocated(0)/1024**3,1), 'GB')\n",
    "        print('Cached:   ', round(torch.cuda.memory_reserved(0)/1024**3,1), 'GB')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "CLASSES = ('plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Main Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "np.random.seed(25)\n",
    "num_classes = 10 \n",
    "\n",
    "# Client training settings\n",
    "localepochs = 12 # The number of epochs for local model training. 50 is the default value    \n",
    "BATCH_SIZE = 64\n",
    "weight_decay = 1e-4\n",
    "\n",
    "# FL settings\n",
    "num_of_clients = 100\n",
    "num_selected = 10\n",
    "num_rounds = 15 # 400 is the default value\n",
    "epochs = 10 # The number of epochs for the clients during FL \n",
    "# batch_size = 32"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Loading the data and preparing data for federated learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "def load_datasets():\n",
    "    \n",
    "    train_transform=transforms.Compose([\n",
    "        transforms.RandomRotation(10),      # rotate +/- 10 degrees\n",
    "        transforms.RandomHorizontalFlip(),  # reverse 50% of images\n",
    "        transforms.Resize(224),             # resize shortest side to 224 pixels\n",
    "        transforms.CenterCrop(224),         # crop longest side to 224 pixels at center\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406],\n",
    "                             [0.229, 0.224, 0.225])\n",
    "    ])\n",
    "    \n",
    "    train_data = torchvision.datasets.ImageFolder(root=(\"/home/rit/LDPFL-main/dataset/archive/\"), transform = train_transform )\n",
    "    \n",
    "    train_indices, test_indices = train_test_split(list(range(len(train_data.targets))), test_size=0.1, stratify=train_data.targets)\n",
    "    train_dataset = torch.utils.data.Subset(train_data, train_indices)\n",
    "    test_dataset = torch.utils.data.Subset(train_data, test_indices)\n",
    "    \n",
    "    n_samples = len(train_dataset) // num_of_clients\n",
    "    class_counts = torch.zeros(6)\n",
    "    for i in range(len(train_dataset)):\n",
    "        class_counts[train_dataset[i][1]] += 1\n",
    "        \n",
    "    \n",
    "    print(\"Checkpoint 1\")\n",
    "\n",
    "    # Divide the samples for each class into n parts\n",
    "    class_indices = {}\n",
    "    for i in range(len(train_dataset)):\n",
    "        label = train_dataset[i][1]\n",
    "        if label not in class_indices:\n",
    "            class_indices[label] = []\n",
    "        class_indices[label].append(i)\n",
    "        \n",
    "    print(\"Checkpoint 2\")\n",
    "\n",
    "    for label in class_indices:\n",
    "        np.random.shuffle(class_indices[label])\n",
    "        class_indices[label] = [class_indices[label][i::num_of_clients] for i in range(num_of_clients)]\n",
    "        \n",
    "    print(\"Checkpoint 3\")\n",
    "\n",
    "    # Create datasets for each client by combining the parts from each class\n",
    "    datasets_list = []\n",
    "    for i in range(num_of_clients):\n",
    "        indices = []\n",
    "        for label in class_indices:\n",
    "            indices += class_indices[label][i]\n",
    "        dataset = torch.utils.data.Subset(train_dataset, indices)\n",
    "        dataloader = torch.utils.data.DataLoader(dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "        datasets_list.append(dataloader)\n",
    "    \n",
    "    test_loader=DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "\n",
    "    # Return train dataloaders and test dataloader\n",
    "    return datasets_list, test_loader\n",
    "\n",
    "\n",
    "\n",
    "trainloaders, testloader = load_datasets()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchsummary import summary\n",
    "\n",
    "net = Net()\n",
    "net.to(device)\n",
    "summary(net, (3, 224, 224))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Federated Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SRR_PARAMS = [\n",
    "#     [0.0, 0.075, 5, 0, 3, 10, 0.1],\n",
    "    [0.0, 0.075, 5, 0, 4, 10, 0.1],\n",
    "    [0.0, 0.075, 5, 0, 5, 10, 0.1],\n",
    "    [0.0, 0.075, 5, 0, 6, 10, 0.1],\n",
    "    [0.0, 0.075, 5, 0, 7, 10, 0.1],\n",
    "    [0.0, 0.075, 5, -30, 4, 10, 0.1],\n",
    "    [0.0, 0.075, 5, -20, 4, 10, 0.1],\n",
    "    [0.0, 0.075, 5, -10, 4, 10, 0.1],\n",
    "    [0.0, 0.075, 5, 0, 4, 10, 0.1],\n",
    "    [0.0, 0.075, 5, 10, 4, 10, 0.1],\n",
    "    [0.0, 0.075, 5, 20, 4, 10, 0.1],\n",
    "    [0.0, 0.075, 5, 30, 4, 10, 0.1],\n",
    "    [0.0, 0.075, 5, 20, 4, 10, 0.1],\n",
    "    [0.0, 0.075, 5, 20, 4, 10, 0.2],\n",
    "    [0.0, 0.075, 5, 20, 4, 10, 0.3],\n",
    "    [0.0, 0.075, 5, 20, 4, 10, 0.4],\n",
    "    [0.0, 0.075, 5, 20, 4, 10, 0.5],\n",
    "    [0.0, 0.075, 5, 20, 4, 10, 0.6],\n",
    "    [0.0, 0.075, 5, 20, 4, 10, 0.7],\n",
    "    [0.0, 0.075, 5, 20, 4, 10, 0.8],\n",
    "    [0.0, 0.075, 5, 20, 4, 10, 0.9],\n",
    "    [0.0, 0.075, 5, 20, 4, 10, 0.95],\n",
    "    [0.0, 0.075, 5, 20, 4, 10, 0.99],\n",
    "    [0.0, 0.075, 5, 20, 4, 10, 1.0]\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for param in SRR_PARAMS:\n",
    "    \n",
    "    with open('medical_mnist_exp.txt', 'a+') as f:\n",
    "        f.write('\\n-------------------------------------------------------------\\n')\n",
    "        # f.write(f'\\nSRR Parameters\\nc = {param[0]}\\nr = {param[1]}\\ne = {param[2]}\\nd = {param[3]}\\np = {param[4]}\\nm = {param[5]}\\nf = {param[6]}\\n\\n')\n",
    "\n",
    "    # print(f'\\nSRR Parameters\\nc = {param[0]}\\nr = {param[1]}\\ne = {param[2]}\\nd = {param[3]}\\np = {param[4]}\\nm = {param[5]}\\nf = {param[6]}\\n\\n')\n",
    "    # Emptying CUDA cache\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "    # Instantiate models and optimizers\n",
    "\n",
    "    # Global Model\n",
    "    global_model = nn.DataParallel(Net()).cuda()\n",
    "\n",
    "    # Client Models as a list\n",
    "    client_models = [nn.DataParallel(Net()) for _ in range(num_of_clients)]\n",
    "\n",
    "    # Initializing client models with global model weights and then saving them as model_x.ckpt where x stands for it's ID\n",
    "    for i, model in enumerate(client_models):\n",
    "        model.load_state_dict(global_model.state_dict())\n",
    "    #     torch.save(model.state_dict(), './models/model_{}.ckpt'.format(i+1))\n",
    "\n",
    "    # Optimizers as a list\n",
    "    opt = [optim.Adam(model.parameters(),lr=0.001) for model in client_models]\n",
    "\n",
    "\n",
    "    if device.type == 'cuda':\n",
    "        for i in range(0,torch.cuda.device_count()):\n",
    "            print(torch.cuda.get_device_name(i))\n",
    "            print('Memory Usage of device :', i)\n",
    "            print('Allocated:', round(torch.cuda.memory_allocated(0)/1024**3,1), 'GB')\n",
    "            print('Cached:   ', round(torch.cuda.memory_reserved(0)/1024**3,1), 'GB')\n",
    "\n",
    "\n",
    "    ldp_func = SRR(c = param[0], r = param[1], epsilon = param[2], delta_d = param[3] , precision = param[4], m = param[5])\n",
    "    # ldp_func = GRR(c = 0.0, r = 0.075, epsilon = 3, precision = 4)\n",
    "\n",
    "\n",
    "    acc_train_collect = []\n",
    "    acc_test_collect = []\n",
    "    loss_train_collect = []\n",
    "    loss_test_collect = []\n",
    "\n",
    "    index = 0\n",
    "\n",
    "    for r in tqdm(range(num_rounds)):\n",
    "\n",
    "        round_start = time.time()\n",
    "        \n",
    "        index += 1\n",
    "        print(f\"Round {index}\\n\")\n",
    "        \n",
    "        # select (num_of_clients - 1) clients randomly\n",
    "        client_idx = np.random.permutation(num_of_clients)[:int(param[6]*num_of_clients)]\n",
    "        \n",
    "        trainloss = 0\n",
    "        trainacc = 0\n",
    "        loss = 0\n",
    "        \n",
    "        count = 0\n",
    "        \n",
    "        # clients update\n",
    "        for i in client_idx:\n",
    "            print(f\"Client {i} training\\n\")\n",
    "            count += 1\n",
    "            \n",
    "            \n",
    "            client_models[i].cuda()\n",
    "            opt_state = opt[i].state_dict()\n",
    "            # new_opt = optim.SGD(client_models[i].parameters(), lr=0.004, momentum=0.9, weight_decay=5e-4)\n",
    "            new_opt = optim.Adam(client_models[i].parameters(), lr=0.001)\n",
    "            new_opt.load_state_dict(opt_state)\n",
    "            \n",
    "            # calling client_update\n",
    "            [loss,acc]= fl.client_update(client_models[i], opt[i], trainloaders[i], epochs, device)  \n",
    "            \n",
    "            client_models[i].to('cpu')\n",
    "            opt[i].load_state_dict(new_opt.state_dict())\n",
    "            \n",
    "            \n",
    "            trainloss += loss\n",
    "            trainacc += acc\n",
    "            \n",
    "            torch.cuda.empty_cache()\n",
    "        \n",
    "        # server aggregate\n",
    "        \n",
    "        start = time.time()\n",
    "        # fl.server_aggregate_ldpfl(global_model, [client_models[i] for i in client_idx], client_models)\n",
    "        # fl.server_aggregate(global_model, [client_models[i] for i in client_idx], client_models)\n",
    "        # fl.server_aggregate_srr(global_model, [client_models[i] for i in client_idx], client_models, ldp_func)\n",
    "        fl.server_aggregate(global_model, [client_models[i] for i in client_idx], client_models)\n",
    "        # fl.server_aggregate_srr(global_model, [client_models[i] for i in client_idx], client_models, ldp_func)\n",
    "        end = time.time()\n",
    "        \n",
    "        \n",
    "        # Testing the global model\n",
    "        test_loss, test_acc = fl.test(global_model, testloader, device)\n",
    "        \n",
    "\n",
    "        print('Avg Train loss %0.3g - Avg Train accuracy: %0.3g  - Test loss %0.3g - Test accuracy: %0.3f' % (trainloss / len(client_idx), trainacc / len(client_idx), test_loss, test_acc))\n",
    "        \n",
    "        round_end = time.time()\n",
    "        print(f\"Time taken for server aggregation : {end-start} seconds.\")\n",
    "        print(f\"Time taken for Total round : {round_end-round_start} seconds.\")\n",
    "        \n",
    "        with open('medical_mnist_exp.txt', 'a+') as f:\n",
    "            f.write(f\"\\nRound {index}\\n\")\n",
    "            f.write('Avg Train loss %0.3g - Avg Train accuracy: %0.3g  - Test loss %0.3g - Test accuracy: %0.3f' % (trainloss / len(client_idx), trainacc / len(client_idx), test_loss, test_acc))\n",
    "            f.write(f\"\\nTime taken for server aggregation : {end-start} seconds.\\n\")\n",
    "            f.write(f\"Time taken for Total round : {round_end-round_start} seconds.\\n\") \n",
    "\n",
    "        acc_train_collect.append(trainacc / len(client_idx))\n",
    "        acc_test_collect.append(test_acc)\n",
    "        loss_train_collect.append(trainloss / len(client_idx))\n",
    "        loss_test_collect.append(test_loss)\n",
    "        print(\"---------------------------------------------------------\\n\")\n",
    "\n",
    "    for model in client_models:\n",
    "        del model\n",
    "    for o in opt:\n",
    "        del o\n",
    "    del global_model\n",
    "\n",
    "    if device.type == 'cuda':\n",
    "        for i in range(0,torch.cuda.device_count()):\n",
    "            print(torch.cuda.get_device_name(i))\n",
    "            print('Memory Usage of device :', i)\n",
    "            print('Allocated:', round(torch.cuda.memory_allocated(0)/1024**3,1), 'GB')\n",
    "            print('Cached:   ', round(torch.cuda.memory_reserved(0)/1024**3,1), 'GB')\n",
    "\n",
    "    print(\"\\n**********************************************************************\\n\")\n",
    "  \n",
    "\n",
    "print(\"Training and Evaluation completed!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# %matplotlib inline\n",
    "\n",
    "x1 = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10]\n",
    "y1 = [58.5, 52.8, 92.2, 90.7, 94.7, 96.2, 94.4, 92.6, 93.9, 95.9]\n",
    "\n",
    "x2 = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10]\n",
    "y2 = [87.8, 95.2, 96.1, 96.4, 96.8, 95.5, 97.3, 97.7, 97.6, 97.9]\n",
    "\n",
    "# plot the data\n",
    "plt.plot(x1, y1, color='red', label='SRR (e=20)')\n",
    "plt.plot(x2, y2, color='blue', label='LDP-FL (e=1)')\n",
    "\n",
    "# set plot title and labels\n",
    "plt.title('SRR vs LDP-FL for 100 clients (FedAvg Settings)')\n",
    "plt.xlabel('Rounds')\n",
    "plt.ylabel('Test Accuracy')\n",
    "\n",
    "# set legend and show plot\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
