{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LDPFL on the MNIST Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook shows how to run LDPFL on the MNIST Dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Importing packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "#!/usr/bin/env python3\n",
    "# -*- coding: utf-8 -*-\n",
    "\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "import torch.nn.functional as F\n",
    "import torchvision.transforms as transforms\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "from torchvision.datasets import MNIST\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data import Dataset, TensorDataset\n",
    "\n",
    "\n",
    "import time\n",
    "import math\n",
    "import statistics\n",
    "import random\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "from scipy.io import loadmat\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from MNIST_FL import FedMLFunc as fl\n",
    "from MNIST_FL import Net as Net\n",
    "fl = fl()\n",
    "\n",
    "from collections import OrderedDict\n",
    "from collections import defaultdict\n",
    "from typing import List, Tuple\n",
    "\n",
    "\n",
    "from LDP_Functions import SRR\n",
    "from LDP_Functions import LDP_FL\n",
    "from LDP_Functions import GRR\n",
    "\n",
    "print(\"numpy\", np.__version__)\n",
    "print(\"torch\", torch.__version__)\n",
    "print(\"torchvision\", torchvision.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# Checking the device\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print('Using device:', device)\n",
    "\n",
    "# Getting GPU usage information before computation\n",
    "if device.type == 'cuda':\n",
    "    for i in range(0,torch.cuda.device_count()):\n",
    "        print(torch.cuda.get_device_name(i))\n",
    "        print('Memory Usage of device :', i)\n",
    "        print('Allocated:', round(torch.cuda.memory_allocated(0)/1024**3,1), 'GB')\n",
    "        print('Cached:   ', round(torch.cuda.memory_reserved(0)/1024**3,1), 'GB')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "CLASSES = ('plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Main Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "np.random.seed(25)\n",
    "num_classes = 10 \n",
    "\n",
    "# Client training settings\n",
    "localepochs = 12   \n",
    "BATCH_SIZE = 16\n",
    "weight_decay = 1e-4\n",
    "\n",
    "# FL settings\n",
    "num_of_clients = 100\n",
    "num_selected = 90\n",
    "num_rounds = 15\n",
    "epochs = 10 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Loading the data and preparing the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "def load_datasets():\n",
    "    \n",
    "    train_dataset = MNIST('./dataset', train=True, download=True, transform=transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.1307,), (0.3081,))\n",
    "    ]))\n",
    "\n",
    "    test_dataset = MNIST('./dataset', train=False, download=True, transform=transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.1307,), (0.3081,))\n",
    "    ]))\n",
    "\n",
    "    n_samples = len(train_dataset) // num_of_clients\n",
    "    class_counts = torch.zeros(10)\n",
    "    for i in range(len(train_dataset)):\n",
    "        class_counts[train_dataset[i][1]] += 1\n",
    "\n",
    "    # Divide the samples for each class into n parts\n",
    "    class_indices = {}\n",
    "    for i in range(len(train_dataset)):\n",
    "        label = train_dataset[i][1]\n",
    "        if label not in class_indices:\n",
    "            class_indices[label] = []\n",
    "        class_indices[label].append(i)\n",
    "\n",
    "    for label in class_indices:\n",
    "        np.random.shuffle(class_indices[label])\n",
    "        class_indices[label] = [class_indices[label][i::num_of_clients] for i in range(num_of_clients)]\n",
    "\n",
    "    # Create datasets for each client by combining the parts from each class\n",
    "    datasets_list = []\n",
    "    for i in range(num_of_clients):\n",
    "        indices = []\n",
    "        for label in class_indices:\n",
    "            indices += class_indices[label][i]\n",
    "        dataset = torch.utils.data.Subset(train_dataset, indices)\n",
    "        dataloader = torch.utils.data.DataLoader(dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "        datasets_list.append(dataloader)\n",
    "\n",
    "    test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "\n",
    "    return datasets_list, test_loader\n",
    "\n",
    "\n",
    "trainloaders, testloader = load_datasets()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchsummary import summary\n",
    "\n",
    "net = Net()\n",
    "net.to(device)\n",
    "summary(net, (1, 28, 28))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Federated Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SRR_PARAMS = [\n",
    "#     [0.0, 0.075, 5, 0, 3, 10, 0.1],\n",
    "    [0.0, 0.075, 5, 0, 4, 10, 0.1],\n",
    "    [0.0, 0.075, 5, 0, 5, 10, 0.1],\n",
    "    [0.0, 0.075, 5, 0, 6, 10, 0.1],\n",
    "    [0.0, 0.075, 5, 0, 7, 10, 0.1],\n",
    "    [0.0, 0.075, 5, -30, 4, 10, 0.1],\n",
    "    [0.0, 0.075, 5, -20, 4, 10, 0.1],\n",
    "    [0.0, 0.075, 5, -10, 4, 10, 0.1],\n",
    "    [0.0, 0.075, 5, 0, 4, 10, 0.1],\n",
    "    [0.0, 0.075, 5, 10, 4, 10, 0.1],\n",
    "    [0.0, 0.075, 5, 20, 4, 10, 0.1],\n",
    "    [0.0, 0.075, 5, 30, 4, 10, 0.1],\n",
    "    [0.0, 0.075, 5, 20, 4, 10, 0.1],\n",
    "    [0.0, 0.075, 5, 20, 4, 10, 0.2],\n",
    "    [0.0, 0.075, 5, 20, 4, 10, 0.3],\n",
    "    [0.0, 0.075, 5, 20, 4, 10, 0.4],\n",
    "    [0.0, 0.075, 5, 20, 4, 10, 0.5],\n",
    "    [0.0, 0.075, 5, 20, 4, 10, 0.6],\n",
    "    [0.0, 0.075, 5, 20, 4, 10, 0.7],\n",
    "    [0.0, 0.075, 5, 20, 4, 10, 0.8],\n",
    "    [0.0, 0.075, 5, 20, 4, 10, 0.9],\n",
    "    [0.0, 0.075, 5, 20, 4, 10, 0.95],\n",
    "    [0.0, 0.075, 5, 20, 4, 10, 0.99],\n",
    "    [0.0, 0.075, 5, 20, 4, 10, 1.0]\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for param in SRR_PARAMS:\n",
    "\n",
    "    print(f'\\nSRR Parameters\\nc = {param[0]}\\nr = {param[1]}\\ne = {param[2]}\\nd = {param[3]}\\np = {param[4]}\\nm = {param[5]}\\nf = {param[6]}\\n\\n')\n",
    "    # Emptying CUDA cache\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "    # Instantiate models and optimizers\n",
    "\n",
    "    # Global Model\n",
    "    global_model = nn.DataParallel(Net()).cuda()\n",
    "\n",
    "    # Client Models as a list\n",
    "    client_models = [nn.DataParallel(Net()).cuda() for _ in range(num_of_clients)]\n",
    "\n",
    "    # Initializing client models with global model weights and then saving them as model_x.ckpt where x stands for it's ID\n",
    "    for i, model in enumerate(client_models):\n",
    "        model.load_state_dict(global_model.state_dict())\n",
    "    #     torch.save(model.state_dict(), './models/model_{}.ckpt'.format(i+1))\n",
    "\n",
    "    # Optimizers as a list\n",
    "    opt = [optim.SGD(model.parameters(), lr=0.1, momentum=0.5) for model in client_models]\n",
    "\n",
    "\n",
    "    if device.type == 'cuda':\n",
    "        for i in range(0,torch.cuda.device_count()):\n",
    "            print(torch.cuda.get_device_name(i))\n",
    "            print('Memory Usage of device :', i)\n",
    "            print('Allocated:', round(torch.cuda.memory_allocated(0)/1024**3,1), 'GB')\n",
    "            print('Cached:   ', round(torch.cuda.memory_reserved(0)/1024**3,1), 'GB')\n",
    "\n",
    "\n",
    "    ldp_func = SRR(c = param[0], r = param[1], epsilon = param[2], delta_d = param[3] , precision = param[4], m = param[5])\n",
    "    # ldp_func = GRR(c = 0.0, r = 0.075, epsilon = 3, precision = 4)\n",
    "\n",
    "\n",
    "    acc_train_collect = []\n",
    "    acc_test_collect = []\n",
    "    loss_train_collect = []\n",
    "    loss_test_collect = []\n",
    "\n",
    "    index = 0\n",
    "\n",
    "    for r in tqdm(range(num_rounds)):\n",
    "\n",
    "        round_start = time.time()\n",
    "        \n",
    "        index += 1\n",
    "        \n",
    "        # select clients randomly\n",
    "        client_idx = np.random.permutation(num_of_clients)[:int(param[6]*num_of_clients)]\n",
    "        \n",
    "        trainloss = 0\n",
    "        trainacc = 0\n",
    "        loss = 0\n",
    "        \n",
    "        count = 0\n",
    "        \n",
    "        # clients update\n",
    "        for i in client_idx:  \n",
    "            count += 1\n",
    "            \n",
    "            # calling client_update\n",
    "            [loss,acc]= fl.client_update(client_models[i], opt[i], trainloaders[i], epochs, device)  \n",
    "            \n",
    "            trainloss += loss\n",
    "            trainacc += acc\n",
    "            \n",
    "            torch.cuda.empty_cache()\n",
    "        \n",
    "        # server aggregate\n",
    "        \n",
    "        start = time.time()\n",
    "    #     fl.server_aggregate_ldpfl(global_model, [client_models[i] for i in client_idx], client_models)\n",
    "    #     fl.server_aggregate(global_model, [client_models[i] for i in client_idx], client_models)\n",
    "        fl.server_aggregate_grr(global_model, [client_models[i] for i in client_idx], client_models, ldp_func)\n",
    "    #     fl.server_aggregate_srr(global_model, [client_models[i] for i in client_idx], client_models, ldp_func)\n",
    "        end = time.time()\n",
    "        \n",
    "        # Testing the global model\n",
    "        test_loss, test_acc = fl.test(global_model, testloader, device)\n",
    "\n",
    "        print(f\"\\nRound {index}\")\n",
    "        print('Avg Train loss %0.3g - Avg Train accuracy: %0.3g  - Test loss %0.3g - Test accuracy: %0.3f' % (trainloss / len(client_idx), trainacc / len(client_idx), test_loss, test_acc))\n",
    "        \n",
    "        round_end = time.time()\n",
    "        print(f\"Time taken for server aggregation : {end-start} seconds.\")\n",
    "        print(f\"Time taken for Total round : {round_end-round_start} seconds.\")\n",
    "\n",
    "        acc_train_collect.append(trainacc / len(client_idx))\n",
    "        acc_test_collect.append(test_acc)\n",
    "        loss_train_collect.append(trainloss / len(client_idx))\n",
    "        loss_test_collect.append(test_loss)\n",
    "        print(\"---------------------------------------------------------\\n\")\n",
    "\n",
    "    for model in client_models:\n",
    "        del model\n",
    "    for o in opt:\n",
    "        del o\n",
    "    del global_model\n",
    "\n",
    "    if device.type == 'cuda':\n",
    "        for i in range(0,torch.cuda.device_count()):\n",
    "            print(torch.cuda.get_device_name(i))\n",
    "            print('Memory Usage of device :', i)\n",
    "            print('Allocated:', round(torch.cuda.memory_allocated(0)/1024**3,1), 'GB')\n",
    "            print('Cached:   ', round(torch.cuda.memory_reserved(0)/1024**3,1), 'GB')\n",
    "\n",
    "    print(\"\\n**********************************************************************\\n\")\n",
    "  \n",
    "\n",
    "print(\"Training and Evaluation completed!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Declaring the models for aggregate attack FL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# Emptying CUDA cache\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "# Instantiate models and optimizers\n",
    "\n",
    "# Global Model\n",
    "global_model = nn.DataParallel(Net()).cuda()\n",
    "global_copy = nn.DataParallel(Net()).cuda()\n",
    "\n",
    "# Client Models as a list\n",
    "client_models = [nn.DataParallel(Net()).cuda() for _ in range(num_of_clients)]\n",
    "\n",
    "\n",
    "for i, model in enumerate(client_models):\n",
    "    model.load_state_dict(global_model.state_dict())\n",
    "\n",
    "# Optimizers as a list\n",
    "opt = [optim.SGD(model.parameters(), lr=0.1, momentum=0.5) for model in client_models]\n",
    "\n",
    "\n",
    "if device.type == 'cuda':\n",
    "    for i in range(0,torch.cuda.device_count()):\n",
    "        print(torch.cuda.get_device_name(i))\n",
    "        print('Memory Usage of device :', i)\n",
    "        print('Allocated:', round(torch.cuda.memory_allocated(0)/1024**3,1), 'GB')\n",
    "        print('Cached:   ', round(torch.cuda.memory_reserved(0)/1024**3,1), 'GB')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from LDP_Functions import SRR\n",
    "from LDP_Functions import LDPFL\n",
    "from LDP_Functions import GRR\n",
    "\n",
    "\n",
    "# ldp_func = SRR(c = 0.0, r = 0.03, epsilon = 5, delta_d = 30 , precision = 5, m = 10)\n",
    "# ldp_func = GRR(c = 0.0, r = 0.075, epsilon = 3, precision = 4)\n",
    "ldp_func = LDPFL(c = 0.0, r = 0.075, epsilon = 10)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Aggregate Attack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false,
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "acc_train_collect = []\n",
    "acc_test_collect = []\n",
    "loss_train_collect = []\n",
    "loss_test_collect = []\n",
    "\n",
    "fl.initialize_history(global_model)\n",
    "\n",
    "index = 0\n",
    "\n",
    "for r in tqdm(range(num_rounds)):\n",
    "    \n",
    "    index += 1\n",
    "    print(f\"Round {index}\")\n",
    "    \n",
    "    # select clients randomly\n",
    "    client_idx = np.random.permutation(num_of_clients)[:num_selected]\n",
    "    \n",
    "    trainloss = 0\n",
    "    trainacc = 0\n",
    "    loss = 0\n",
    "    \n",
    "    count = 0\n",
    "    \n",
    "    # clients update\n",
    "    for i in client_idx:  \n",
    "        count += 1\n",
    "        \n",
    "        # calling client_update\n",
    "        [loss,acc]= fl.client_update(client_models[i], opt[i], trainloaders[i], epochs, device)  \n",
    "        \n",
    "        print(f\"{count}.  Client{i+1} \\t Training Loss: {loss} \\t Training Accuracy: {acc}\\n\")\n",
    "        \n",
    "        trainloss += loss\n",
    "        trainacc += acc\n",
    "        \n",
    "        torch.cuda.empty_cache()\n",
    "    \n",
    "    # server aggregate\n",
    "    \n",
    "    start = time.time()\n",
    "    \n",
    "    mean_error, successes = fl.server_aggregate_attack(global_model, global_copy, [client_models[i] for i in client_idx], client_models, ldp_func, error_bound = 0.01, score = 95.0)\n",
    "\n",
    "    end = time.time()\n",
    "    \n",
    "    print(f\"Mean Error : {mean_error}\\nSuccess Count : {successes}\")\n",
    "    \n",
    "    print(f\"Time taken for server aggregation : {end-start} seconds.\")\n",
    "    \n",
    "    # Testing the global model\n",
    "    test_loss, test_acc = fl.test(global_model, testloader, device)\n",
    "    \n",
    "\n",
    "    print(f\"Round {index}\")\n",
    "    print('Avg Train loss %0.3g - Avg Train accuracy: %0.3g  - Test loss %0.3g - Test accuracy: %0.3f' % (trainloss / len(client_idx), trainacc / len(client_idx), test_loss, test_acc))\n",
    "    \n",
    "    acc_train_collect.append(trainacc / len(client_idx))\n",
    "    acc_test_collect.append(test_acc)\n",
    "    loss_train_collect.append(trainloss / len(client_idx))\n",
    "    loss_test_collect.append(test_loss)\n",
    "    print(\"---------------------------------------------------------\\n\")\n",
    "    \n",
    "if device.type == 'cuda':\n",
    "    for i in range(0,torch.cuda.device_count()):\n",
    "        print(torch.cuda.get_device_name(i))\n",
    "        print('Memory Usage of device :', i)\n",
    "        print('Allocated:', round(torch.cuda.memory_allocated(0)/1024**3,1), 'GB')\n",
    "        print('Cached:   ', round(torch.cuda.memory_reserved(0)/1024**3,1), 'GB')\n",
    "\n",
    "print(\"Training and Evaluation completed!\") "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# %matplotlib inline\n",
    "\n",
    "x1 = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10]\n",
    "y1 = [58.5, 52.8, 92.2, 90.7, 94.7, 96.2, 94.4, 92.6, 93.9, 95.9]\n",
    "\n",
    "x2 = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10]\n",
    "y2 = [87.8, 95.2, 96.1, 96.4, 96.8, 95.5, 97.3, 97.7, 97.6, 97.9]\n",
    "\n",
    "# plot the data\n",
    "plt.plot(x1, y1, color='red', label='SRR (e=20)')\n",
    "plt.plot(x2, y2, color='blue', label='LDP-FL (e=1)')\n",
    "\n",
    "# set plot title and labels\n",
    "plt.title('SRR vs LDP-FL for 100 clients (FedAvg Settings)')\n",
    "plt.xlabel('Rounds')\n",
    "plt.ylabel('Test Accuracy')\n",
    "\n",
    "# set legend and show plot\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
