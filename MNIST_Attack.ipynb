{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<frozen importlib._bootstrap>:219: RuntimeWarning: scipy._lib.messagestream.MessageStream size changed, may indicate binary incompatibility. Expected 56 from C header, got 64 from PyObject\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "numpy 1.24.4\n",
      "torch 1.12.1\n",
      "torchvision 0.13.1\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python3\n",
    "# -*- coding: utf-8 -*-\n",
    "\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "import torch.nn.functional as F\n",
    "import torchvision.transforms as transforms\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "from torchvision.datasets import MNIST\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data import Dataset, TensorDataset\n",
    "\n",
    "import time\n",
    "import math\n",
    "import statistics\n",
    "import random\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.io import loadmat\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from MNIST_FL import FedMLFunc as fl\n",
    "from MNIST_FL import Net as Net\n",
    "from tqdm import tqdm\n",
    "fl = fl()\n",
    "\n",
    "from collections import OrderedDict\n",
    "from collections import defaultdict\n",
    "from typing import List, Tuple\n",
    "\n",
    "from LDP_Functions import SRR\n",
    "from LDP_Functions import LDP_FL\n",
    "from LDP_Functions import GRR\n",
    "\n",
    "print(\"numpy\", np.__version__)\n",
    "print(\"torch\", torch.__version__)\n",
    "print(\"torchvision\", torchvision.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking the device\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print('Using device:', device)\n",
    "\n",
    "# Getting GPU usage information before computation\n",
    "if device.type == 'cuda':\n",
    "    for i in range(0,torch.cuda.device_count()):\n",
    "        print(torch.cuda.get_device_name(i))\n",
    "        print('Memory Usage of device :', i)\n",
    "        print('Allocated:', round(torch.cuda.memory_allocated(0)/1024**3,1), 'GB')\n",
    "        print('Cached:   ', round(torch.cuda.memory_reserved(0)/1024**3,1), 'GB')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CLASSES = ('plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(25)\n",
    "num_classes = 10 \n",
    "\n",
    "# Client training settings\n",
    "localepochs = 12 # The number of epochs for local model training. 50 is the default value  \n",
    "BATCH_SIZE = 16  \n",
    "weight_decay = 1e-4\n",
    "\n",
    "# FL settings\n",
    "num_of_clients = 500\n",
    "num_selected = 500\n",
    "num_rounds = 50 \n",
    "epochs = 10 # The number of epochs for the clients during FL "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_datasets():\n",
    "    \n",
    "    train_dataset = MNIST('./dataset', train=True, download=True, transform=transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.1307,), (0.3081,))\n",
    "    ]))\n",
    "\n",
    "    test_dataset = MNIST('./dataset', train=False, download=True, transform=transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.1307,), (0.3081,))\n",
    "    ]))\n",
    "\n",
    "    n_samples = len(train_dataset) // num_of_clients\n",
    "    class_counts = torch.zeros(10)\n",
    "    for i in range(len(train_dataset)):\n",
    "        class_counts[train_dataset[i][1]] += 1\n",
    "\n",
    "    # Divide the samples for each class into n parts\n",
    "    class_indices = {}\n",
    "    for i in range(len(train_dataset)):\n",
    "        label = train_dataset[i][1]\n",
    "        if label not in class_indices:\n",
    "            class_indices[label] = []\n",
    "        class_indices[label].append(i)\n",
    "\n",
    "    for label in class_indices:\n",
    "        np.random.shuffle(class_indices[label])\n",
    "        class_indices[label] = [class_indices[label][i::num_of_clients] for i in range(num_of_clients)]\n",
    "\n",
    "    # Create datasets for each client by combining the parts from each class\n",
    "    datasets_list = []\n",
    "    for i in range(num_of_clients):\n",
    "        indices = []\n",
    "        for label in class_indices:\n",
    "            indices += class_indices[label][i]\n",
    "        dataset = torch.utils.data.Subset(train_dataset, indices)\n",
    "        dataloader = torch.utils.data.DataLoader(dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "        datasets_list.append(dataloader)\n",
    "\n",
    "    test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "\n",
    "    return datasets_list, test_loader\n",
    "\n",
    "\n",
    "trainloaders, testloader = load_datasets()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchsummary import summary\n",
    "\n",
    "net = Net()\n",
    "net.to(device)\n",
    "summary(net, (1, 28, 28))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()\n",
    "\n",
    "# Instantiate models and optimizers\n",
    "\n",
    "# Global Model\n",
    "global_model = nn.DataParallel(Net()).cuda()\n",
    "global_copy = nn.DataParallel(Net()).cuda()\n",
    "\n",
    "# Client Models as a list\n",
    "client_models = [nn.DataParallel(Net()).cuda() for _ in range(num_of_clients)]\n",
    "\n",
    "# Initializing client models with global model weights and then saving them as model_x.ckpt where x stands for it's ID\n",
    "for i, model in enumerate(client_models):\n",
    "    model.load_state_dict(global_model.state_dict())\n",
    "\n",
    "global_copy.load_state_dict(global_model.state_dict())\n",
    "\n",
    "# Optimizers as a list\n",
    "opt = [optim.SGD(model.parameters(), lr=0.1, momentum=0.5) for model in client_models]\n",
    "\n",
    "\n",
    "if device.type == 'cuda':\n",
    "    for i in range(0,torch.cuda.device_count()):\n",
    "        print(torch.cuda.get_device_name(i))\n",
    "        print('Memory Usage of device :', i)\n",
    "        print('Allocated:', round(torch.cuda.memory_allocated(0)/1024**3,1), 'GB')\n",
    "        print('Cached:   ', round(torch.cuda.memory_reserved(0)/1024**3,1), 'GB')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from LDP_Functions import SRR\n",
    "from LDP_Functions import LDP_FL\n",
    "from LDP_Functions import GRR\n",
    "from LDP_Functions import LDPFL\n",
    "\n",
    "\n",
    "# ldp_func = SRR(c = 0.0, r = 0.075, epsilon = 5, delta_d = 20 , precision = 4, m = 10)\n",
    "ldp_func = LDPFL(c = 0.0, r = 0.075, epsilon = 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "acc_train_collect = []\n",
    "acc_test_collect = []\n",
    "loss_train_collect = []\n",
    "loss_test_collect = []\n",
    "\n",
    "index = 0\n",
    "\n",
    "fl.initialize_history(global_model)\n",
    "\n",
    "for r in tqdm(range(num_rounds)):\n",
    "    \n",
    "    index += 1\n",
    "    \n",
    "    # select (num_of_clients - 1) clients randomly\n",
    "    client_idx = np.random.permutation(num_of_clients)[:num_selected]\n",
    "    \n",
    "    trainloss = 0\n",
    "    trainacc = 0\n",
    "    loss = 0\n",
    "    \n",
    "    count = 0\n",
    "    \n",
    "    # clients update\n",
    "    for i in client_idx:  \n",
    "        count += 1\n",
    "        \n",
    "        \n",
    "        # calling client_update\n",
    "        [loss,acc]= fl.client_update(client_models[i], opt[i], trainloaders[i], epochs, device)  \n",
    "        \n",
    "        trainloss += loss\n",
    "        trainacc += acc\n",
    "        \n",
    "        torch.cuda.empty_cache()\n",
    "    \n",
    "    # server aggregate\n",
    "    \n",
    "    start = time.time()\n",
    "#     fl.server_aggregate_grr(global_model, [client_models[i] for i in client_idx], client_models, ldp_func)\n",
    "    tot_count, method1 = fl.server_aggregate_attack(global_model, global_copy, [client_models[i] for i in client_idx], client_models, ldp_func, error_bound=0.001)\n",
    "#     fl.server_aggregate_srr(global_model, [client_models[i] for i in client_idx], client_models, ldp_func)\n",
    "    end = time.time()\n",
    "    \n",
    "    print(f\"Time taken for server aggregation : {end-start} seconds.\")\n",
    "    print(f\"-----------------------------------\\nAttack Results for Round {index}\\n\")\n",
    "    print(f\"Percentage of correct estimations by method 1 : {float(method1)/tot_count}\")\n",
    "#     print(f\"Percentage of correct estimations by method 2 (Mean of historical weights as estimate) : {float(method2)/tot_count}\")\n",
    "#     print(f\"Percentage of estimations estimated to be right : {float(pred_count)/tot_count}\\n\")\n",
    "    print(f\"-----------------------------------\\n\")\n",
    "    \n",
    "if device.type == 'cuda':\n",
    "    for i in range(0,torch.cuda.device_count()):\n",
    "        print(torch.cuda.get_device_name(i))\n",
    "        print('Memory Usage of device :', i)\n",
    "        print('Allocated:', round(torch.cuda.memory_allocated(0)/1024**3,1), 'GB')\n",
    "        print('Cached:   ', round(torch.cuda.memory_reserved(0)/1024**3,1), 'GB')\n",
    "\n",
    "print(\"Training and Evaluation completed!\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random \n",
    "import math \n",
    "def perturb_value(c, r, epsilon): \n",
    "    # Generate a random value within the range [c-r, c+r] \n",
    "    w = random.uniform(c-r, c+r) \n",
    "    result1 = 0 \n",
    "    result2 = 0 \n",
    "    for i in range (1000): \n",
    "        # Compute the perturbation probability \n",
    "        prob = (w - c) * (math.exp(epsilon)-1) + r * (math.exp(epsilon)+1) \n",
    "        prob /= 2 * r * (math.exp(epsilon)+1) \n",
    "        # Generate a random number to decide whether to perturb positively or negatively \n",
    "        if random.random() <= prob: \n",
    "            perturbed_value = c + r * (math.exp(epsilon)+1) / (math.exp(epsilon)-1) \n",
    "            result1 = result1 +1 \n",
    "        else: \n",
    "            perturbed_value = c - r * (math.exp(epsilon)+1) / (math.exp(epsilon)-1) \n",
    "            result2 = result2 +1 \n",
    "    return w, result1/result2 \n",
    "\n",
    "original_w = [] \n",
    "estimated_w = [] \n",
    "c=100 \n",
    "r=90 \n",
    "T=0 \n",
    "epsilon = 1 \n",
    "for i in range(100): \n",
    "    w, ratio = perturb_value(c, r, epsilon) \n",
    "    original_w.append(w) \n",
    "    w_est = (0.5*ratio-0.5)/(1+ratio)*2*r*(math.exp(epsilon)+1)/(math.exp(epsilon)-1)+c \n",
    "    estimated_w.append(w_est) count = 0 for i in range(100): if original_w[i]-estimated_w[i]<= T: count = count+1 print(count/100)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
